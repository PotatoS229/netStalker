# Энциклопедия Docker: От нуля до уверенного использования

## Введение в контейнеризацию

### Что такое Docker и зачем он нужен?

Docker — это платформа для разработки, доставки и запуска приложений в контейнерах. Контейнеры представляют собой изолированные пользовательские пространства, которые содержат всё необходимое для работы приложения: код, среду выполнения, системные инструменты, библиотеки и настройки.

**Почему Docker стал стандартом индустрии:**

1. **Изоляция окружений** — "У меня работает" перестает быть проблемой
2. **Повторяемость** — идентичная среда на всех этапах: разработка, тестирование, продакшен
3. **Эффективность** — контейнеры легче виртуальных машин, быстрее запускаются
4. **Масштабируемость** — основа для микросервисной архитектуры и оркестрации
5. **Упрощение деплоя** — один образ работает везде

## Установка и настройка Docker

### Установка на различные операционные системы

**Arch Linux / Manjaro:**
```bash
# Обновление системы и установка Docker
sudo pacman -Syu
sudo pacman -S docker docker-compose docker-buildx

# Включение и запуск службы Docker
sudo systemctl enable docker
sudo systemctl start docker

# Проверка установки
docker --version
docker-compose --version
```

**Ubuntu / Debian:**
```bash
# Установка зависимостей
sudo apt-get update
sudo apt-get install apt-transport-https ca-certificates curl software-properties-common

# Добавление GPG-ключа Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# Добавление репозитория Docker
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

# Установка Docker
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Добавление пользователя в группу docker (чтобы не использовать sudo)
sudo usermod -aG docker $USER
# После этого нужно перелогиниться
```

**macOS:**
```bash
# Установка через Homebrew
brew install docker docker-compose
# Или скачать Docker Desktop с официального сайта
```

**Windows:**
- Docker Desktop для Windows (WSL2 рекомендован)
- Требуется включение виртуализации в BIOS/UEFI

### Проверка установки
```bash
# Проверка версии
docker version

# Запуск тестового контейнера
docker run hello-world

# Проверка работы демона
sudo systemctl status docker  # Linux
```

## Фундаментальные концепции Docker

### 1. Docker Образ (Image)
**Образ** — это шаблон только для чтения с инструкциями для создания контейнера. Образы состоят из слоев, каждый слой представляет изменение в файловой системе.

**Основные команды для работы с образами:**
```bash
# Поиск образа в Docker Hub
docker search nginx

# Загрузка образа
docker pull nginx:latest

# Просмотр локальных образов
docker images
# Или
docker image ls

# Удаление образа
docker rmi <image_id>
# Принудительное удаление
docker rmi -f <image_id>

# Просмотр истории образа
docker history <image_name>

# Сохранение образа в файл
docker save -o myimage.tar <image_name>

# Загрузка образа из файла
docker load -i myimage.tar

# Тегирование образа
docker tag <old_name> <new_name>:<tag>
```

### 2. Docker Контейнер (Container)
**Контейнер** — это работающий экземпляр образа. Каждый контейнер изолирован и имеет свою файловую систему, сеть и пространство процессов.

**Команды управления контейнерами:**
```bash
# Запуск контейнера
docker run [опции] <образ> [команда]

# Основные опции команды run:
-d, --detach        # Запустить в фоновом режиме
--name <name>       # Присвоить имя контейнеру
-p <host>:<cont>    # Проброс портов
-v <host>:<cont>    # Монтирование томов
-e <KEY=VALUE>      # Установка переменных окружения
--rm                # Автоматически удалить после остановки
-it                 # Интерактивный режим с TTY

# Примеры:
docker run -d --name webserver -p 80:80 nginx
docker run -it --rm ubuntu bash
docker run -e MYSQL_ROOT_PASSWORD=password mysql

# Просмотр контейнеров
docker ps           # Только работающие
docker ps -a        # Все контейнеры
docker ps -q        # Только ID

# Управление контейнерами
docker start <container>    # Запуск остановленного
docker stop <container>     # Остановка (корректная)
docker restart <container>  # Перезапуск
docker kill <container>     # Принудительная остановка
docker pause <container>    # Приостановка
docker unpause <container>  # Возобновление

# Взаимодействие с контейнером
docker exec -it <container> bash  # Запуск bash внутри контейнера
docker logs <container>           # Просмотр логов
docker logs -f <container>        # Просмотр логов в реальном времени
docker logs --tail 50 <container> # Последние 50 строк логов

# Копирование файлов
docker cp <container>:<path> <host_path>   # Из контейнера на хост
docker cp <host_path> <container>:<path>   # С хоста в контейнер

# Просмотр информации
docker inspect <container>    # Подробная информация в JSON
docker stats <container>      # Статистика использования ресурсов
docker top <container>        # Процессы внутри контейнера

# Удаление контейнеров
docker rm <container>         # Удаление остановленного
docker rm -f <container>      # Принудительное удаление
docker container prune        # Удаление всех остановленных контейнеров
```

### 3. Dockerfile — создание своих образов
**Dockerfile** — это текстовый файл с инструкциями для сборки образа.

**Структура Dockerfile:**
```dockerfile
# Базовый образ
FROM ubuntu:22.04

# Метаданные
LABEL maintainer="your.email@example.com"
LABEL version="1.0"
LABEL description="Мой первый Docker образ"

# Рабочая директория внутри контейнера
WORKDIR /app

# Копирование файлов
COPY package.json ./
COPY src ./src

# Установка зависимостей
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Установка Python зависимостей
RUN pip3 install -r requirements.txt

# Переменные окружения
ENV NODE_ENV=production
ENV PORT=3000

# Открытие порта
EXPOSE 3000

# Точка входа (команда запуска)
CMD ["python3", "app.py"]

# Или для интерактивных приложений
# ENTRYPOINT ["python3"]
# CMD ["app.py"]
```

**Инструкции Dockerfile:**
- `FROM` — базовый образ
- `RUN` — выполнение команды при сборке
- `COPY`/`ADD` — копирование файлов
- `WORKDIR` — установка рабочей директории
- `ENV` — установка переменных окружения
- `EXPOSE` — объявление портов
- `CMD` — команда по умолчанию при запуске
- `ENTRYPOINT` — основная исполняемая команда
- `ARG` — аргументы сборки (только во время сборки)
- `USER` — пользователь для запуска команд
- `VOLUME` — создание точки монтирования
- `HEALTHCHECK` — проверка здоровья контейнера

**Сборка образа:**
```bash
# Базовая сборка
docker build -t myapp:latest .

# Сборка с указанием Dockerfile
docker build -f Dockerfile.prod -t myapp:prod .

# Сборка с кэшированием (используется по умолчанию)
docker build --no-cache -t myapp:nocache .  # Без кэша

# Сборка с целевой стадией (для многостадийных сборок)
docker build --target builder -t myapp:builder .

# Просмотр истории сборки
docker history myapp:latest
```

### 4. Docker Volumes — управление данными
**Тома (Volumes)** — предпочтительный способ хранения данных, созданных и используемых контейнерами.

**Типы хранения данных:**
1. **Тома (Volumes)** — управляются Docker, хранятся в `/var/lib/docker/volumes/`
2. **Bind mounts** — монтирование директорий хоста
3. **tmpfs mounts** — хранение в памяти (только Linux)

**Работа с томами:**
```bash
# Создание тома
docker volume create myvolume

# Просмотр томов
docker volume ls

# Информация о томе
docker volume inspect myvolume

# Удаление тома
docker volume rm myvolume
docker volume prune  # Удаление неиспользуемых томов

# Использование томов
docker run -d \
  --name mysql \
  -v mysql_data:/var/lib/mysql \  # Том
  -v /host/path:/container/path \ # Bind mount
  mysql:8.0
```

**Пример использования в Dockerfile:**
```dockerfile
FROM mysql:8.0
VOLUME /var/lib/mysql  # Точка монтирования для данных
```

### 5. Docker Network — сетевые взаимодействия
**Сети Docker** позволяют контейнерам общаться между собой и с внешним миром.

**Типы сетей:**
1. **bridge** — сеть по умолчанию для контейнеров
2. **host** — использование сети хоста
3. **none** — без сети
4. **overlay** — для кластеров (Swarm)
5. **macvlan** — назначение MAC-адресов контейнерам

**Команды для работы с сетями:**
```bash
# Создание сети
docker network create mynetwork

# Просмотр сетей
docker network ls

# Информация о сети
docker network inspect mynetwork

# Подключение контейнера к сети
docker network connect mynetwork mycontainer

# Отключение от сети
docker network disconnect mynetwork mycontainer

# Удаление сети
docker network rm mynetwork
docker network prune  # Удаление неиспользуемых сетей

# Пример запуска контейнеров в одной сети
docker network create app_network
docker run -d --name db --network app_network mysql
docker run -d --name app --network app_network -p 80:3000 myapp
```

### 6. Docker Compose — оркестрация многоконтейнерных приложений
**Docker Compose** — инструмент для определения и запуска многоконтейнерных приложений.

**Файл docker-compose.yml:**
```yaml
version: '3.8'

services:
  # Сервис веб-приложения
  web:
    build: .
    container_name: myapp_web
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgres://user:pass@db:5432/mydb
    volumes:
      - ./src:/app/src
      - node_modules:/app/node_modules
    depends_on:
      - db
      - redis
    networks:
      - app_network
    restart: unless-stopped

  # Сервис базы данных
  db:
    image: postgres:15
    container_name: myapp_db
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: mydb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Сервис Redis
  redis:
    image: redis:alpine
    container_name: myapp_redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - app_network

  # Сервис для миграций (запускается один раз)
  migrate:
    build: .
    command: npm run migrate
    depends_on:
      db:
        condition: service_healthy
    networks:
      - app_network

# Тома
volumes:
  postgres_data:
  redis_data:
  node_modules:

# Сети
networks:
  app_network:
    driver: bridge
```

**Команды Docker Compose:**
```bash
# Запуск всех сервисов
docker-compose up -d

# Запуск конкретного сервиса
docker-compose up -d web

# Остановка всех сервисов
docker-compose down

# Остановка с удалением томов
docker-compose down -v

# Просмотр логов
docker-compose logs
docker-compose logs -f web  # Логи конкретного сервиса в реальном времени

# Выполнение команд в сервисе
docker-compose exec web bash
docker-compose exec db psql -U user mydb

# Пересборка образов
docker-compose build
docker-compose build --no-cache

# Просмотр статуса сервисов
docker-compose ps

# Масштабирование сервиса
docker-compose up -d --scale web=3

# Проверка конфигурации
docker-compose config

# Остановка без удаления контейнеров
docker-compose stop

# Запуск остановленных контейнеров
docker-compose start

# Перезапуск сервисов
docker-compose restart
```

## Продвинутые темы Docker

### 1. Многостадийные сборки (Multi-stage builds)
```dockerfile
# Стадия сборки
FROM node:18 AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY src ./src
RUN npm run build

# Стадия продакшена
FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/package*.json ./
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
USER node
EXPOSE 3000
CMD ["node", "dist/index.js"]
```

### 2. Healthcheck — проверка здоровья
```dockerfile
FROM nginx:alpine
COPY nginx.conf /etc/nginx/nginx.conf
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1
```

### 3. Docker Registry — работа с реестрами
```bash
# Логин в Docker Hub
docker login
docker login registry.example.com

# Пуш образа в реестр
docker tag myapp:latest username/myapp:1.0
docker push username/myapp:1.0

# Пулл из частного реестра
docker pull registry.example.com/myapp:1.0

# Создание локального реестра
docker run -d -p 5000:5000 --name registry registry:2

# Пуш в локальный реестр
docker tag myapp:latest localhost:5000/myapp:latest
docker push localhost:5000/myapp:latest
```

### 4. Docker Buildx — расширенные возможности сборки
```bash
# Создание builder
docker buildx create --name mybuilder --use

# Сборка для нескольких архитектур
docker buildx build --platform linux/amd64,linux/arm64 -t myapp:multiarch .

# Просмотр текущего builder
docker buildx ls

# Сборка и пуш
docker buildx build --platform linux/amd64,linux/arm64 \
  -t username/myapp:latest --push .
```

### 5. Docker Secrets — управление секретами
```bash
# Создание секрета
echo "mysecretpassword" | docker secret create db_password -

# Использование в Docker Compose
# docker-compose.yml
version: '3.8'
services:
  db:
    image: mysql:8.0
    secrets:
      - db_password
    environment:
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_password

secrets:
  db_password:
    external: true
```

## Best Practices

### 1. Безопасность
```dockerfile
# Используйте официальные базовые образы
FROM alpine:3.18

# Не запускайте контейнеры от root
RUN addgroup -g 1000 appuser && \
    adduser -u 1000 -G appuser -s /bin/sh -D appuser
USER appuser

# Обновляйте пакеты
RUN apk update && apk upgrade

# Удаляйте кэш пакетного менеджера
RUN npm ci --only=production && \
    npm cache clean --force

# Используйте .dockerignore
# .dockerignore
node_modules
.git
*.log
.env
Dockerfile
README.md
```

### 2. Оптимизация образов
```dockerfile
# Используйте легкие базовые образы
FROM alpine:3.18  # вместо ubuntu

# Объединяйте RUN команды
RUN apt-get update && \
    apt-get install -y package1 package2 && \
    rm -rf /var/lib/apt/lists/*

# Используйте многостадийные сборки
# Копируйте только необходимые файлы
COPY package.json package-lock.json ./
RUN npm ci --only=production
COPY src ./src

# Используйте специфичные теги
FROM node:18-alpine  # вместо node:latest
```

### 3. Организация
```yaml
# docker-compose.override.yml для разработки
version: '3.8'
services:
  web:
    volumes:
      - ./src:/app/src
      - ./nodemon.json:/app/nodemon.json
    command: npm run dev
    environment:
      - NODE_ENV=development
      - DEBUG=true
```

## Практические примеры

### 1. Веб-приложение Node.js + PostgreSQL + Nginx
```yaml
# docker-compose.yml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    networks:
      - webnet

  app:
    build: ./app
    environment:
      - DATABASE_URL=postgres://user:pass@db:5432/appdb
      - REDIS_URL=redis://redis:6379
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - webnet
      - backend

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: appdb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - backend

  adminer:
    image: adminer
    ports:
      - "8080:8080"
    networks:
      - backend

volumes:
  postgres_data:
  redis_data:

networks:
  webnet:
    driver: bridge
  backend:
    driver: bridge
```

### 2. Python приложение с Celery и Flower
```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    command: gunicorn app.wsgi:application --bind 0.0.0.0:8000
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
      - postgres
    volumes:
      - static_volume:/app/static
      - media_volume:/app/media

  celery:
    build: .
    command: celery -A app worker --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
      - web

  celery-beat:
    build: .
    command: celery -A app beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - redis
      - web

  flower:
    image: mher/flower
    ports:
      - "5555:5555"
    command: celery flower --broker=redis://redis:6379/0
    depends_on:
      - redis
      - celery

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: appdb
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - static_volume:/app/static
    depends_on:
      - web

volumes:
  postgres_data:
  static_volume:
  media_volume:
```

## Мониторинг и отладка

### Команды для мониторинга:
```bash
# Общая статистика
docker stats

# Использование ресурсов
docker system df
docker system df -v

# Просмотр событий Docker
docker events

# Информация о системе
docker info

# Проверка здоровья всех контейнеров
docker ps --format "table {{.Names}}\t{{.Status}}"

# Анализ образа
docker image inspect <image>
docker history <image>

# Анализ контейнера
docker container inspect <container>
```

### Логирование:
```bash
# Различные драйверы логов
docker run --log-driver json-file --log-opt max-size=10m nginx
docker run --log-driver syslog nginx
docker run --log-driver journald nginx

# Просмотр логов с фильтрацией
docker logs --since 1h <container>
docker logs --until 5m <container>
docker logs -t <container>  # С метками времени
```

## Миграция и бэкапы

```bash
# Экспорт контейнера
docker export <container> > container.tar

# Импорт контейнера
cat container.tar | docker import - myimage:imported

# Бэкап тома
docker run --rm -v myvolume:/volume -v $(pwd):/backup alpine \
  tar czf /backup/backup.tar.gz -C /volume ./

# Восстановление тома
docker run --rm -v myvolume:/volume -v $(pwd):/backup alpine \
  sh -c "rm -rf /volume/* && tar xzf /backup/backup.tar.gz -C /volume"

# Миграция контейнера между хостами
docker save myimage:latest | gzip > myimage.tar.gz
# Переносим файл на другой хост
docker load < myimage.tar.gz
```

## Полезные утилиты и инструменты
Ну что же, сдесь я бубу вам рассказывать про Docker.
Мое мнение максимально простое, без докера, вы как программист слабый, лучше не знать SQL, но Docker должен знать каждый

Docker решает фундаментальные проблемы разработки, которые раньше отнимали львиную долю времени и нервов.

Почему без Docker'a программист "слабый" (или, скорее, менее эффективный)?

Потому что он тратит силы не на код, а на борьбу со средой:

    "А у меня работает!" (Проблема окружения). Самая классическая. На маке работает, на Windows падает, на Linux-сервере другая версия библиотеки. Программист без Docker'а вынужден быть системным администратором для своего приложения.

    "Как запустить этот старый проект?" Нужно поставить конкретную версию Node.js/Python/Java, конкретную СУБД. Вспоминать, как это всё связать. Дни уходят на настройку.

    "Давайте обновим версию PHP на сервере..." А это ломает три других проекта. Без изоляции всё живёт в одной песочнице, что чревато конфликтами.

    Онбординг нового разработчика. Новый человек в команде тратит не час, а день или два, чтобы настроить среду, прочитать README с 20 шагами и всё-таки что-то упустить.

    Неповторимость деплоя. То, что вы настраиваете вручную на сервере, невозможно точно повторить. Это — риск.

И на этих словах, я начинаю курс по Docker

Для начала давайте установим Docker Engine - это клиент-серверное приложение
Docker Engine состоит из трех основных компонентов:
1. Сервер, на котором запускается фоновый процесс демон .
2. REST API (Representational State Transfer Application ProgrammingНу что же, сдесь я бубу вам рассказывать про Docker.
Мое мнение максимально простое, без докера, вы как программист слабый, лучше не знать SQL, но Docker должен знать каждый

Docker решает фундаментальные проблемы разработки, которые раньше отнимали львиную долю времени и нервов.

Почему без Docker'a программист "слабый" (или, скорее, менее эффективный)?

Потому что он тратит силы не на код, а на борьбу со средой:

    "А у меня работает!" (Проблема окружения). Самая классическая. На маке работает, на Windows падает, на Linux-сервере другая версия библиотеки. Программист без Docker'а вынужден быть системным администратором для своего приложения.

    "Как запустить этот старый проект?" Нужно поставить конкретную версию Node.js/Python/Java, конкретную СУБД. Вспоминать, как это всё связать. Дни уходят на настройку.

    "Давайте обновим версию PHP на сервере..." А это ломает три других проекта. Без изоляции всё живёт в одной песочнице, что чревато конфликтами.

    Онбординг нового разработчика. Новый человек в команде тратит не час, а день или два, чтобы настроить среду, прочитать README с 20 шагами и всё-таки что-то упустить.

    Неповторимость деплоя. То, что вы настраиваете вручную на сервере, невозможно точно повторить. Это — риск.

И на этих словах, я начинаю курс по Docker

Для начала давайте установим Docker Engine - это клиент-серверное приложение
Docker Engine состоит из трех основных компонентов:
1. Сервер, на котором запускается фоновый процесс демон .
2. REST API (Representational State Transfer Application Programming lnterface -
передача репрезентативного состояния программного интерфейса приложения),
который управляет взаимодействием программ с демоном Docker и пр.
3. Простейший интерфейс командной строки Docker.

Для Arch0Linux, для других операционок смотрите на офицеальном сайте 
```bash
# Обновляем систему
sudo pacman -Syu

# Устанавливаем docker, docker-compose и дополнительные утилиты
sudo pacman -S docker docker-compose docker-buildx

# Или минимальный набор:
sudo pacman -S docker docker-compose
```

Пока у вас все скачивается, а это не очень быстрый процесс, хочу вам рассказать о важных вещах
Docker Hub и Docker Registry

Реестр (Registry)- это система хранения и доставки данных. В случае с Docker
речь идет о хранении образов с использованием тегов. Помимо сервиса Docker
Registry для этой цели можно использовать сторонний публичный или закрытый
(private) реестр, например Docker НиЬ , АWS Container Registry, Google Container
Registry и т. д.
У одного образа может быть несколько версий с разными тегами. В реестр образы
загружаются с помощью команды push, а извлекаются из него помощью команды pull. lnterface -
передача репрезентативного состояния программного интерфейса приложения),
который управляет взаимодействием программ с демоном Docker и пр.
3. Простейший интерфейс командной строки Docker.

Для Arch0Linux, для других операционок смотрите на офицеальном сайте 
```bash
# Обновляем систему
sudo pacman -Syu

# Устанавливаем docker, docker-compose и дополнительные утилиты
sudo pacman -S docker docker-compose docker-buildx

# Или минимальный набор:
sudo pacman -S docker docker-compose
```

Пока у вас все скачивается, а это не очень быстрый процесс, хочу вам рассказать о важных вещах
Docker Hub и Docker Registry

Реестр (Registry)- это система хранения и доставки данных. В случае с Docker
речь идет о хранении образов с использованием тегов. Помимо сервиса Docker
Registry для этой цели можно использовать сторонний публичный или закрытый
(private) реестр, например Docker НиЬ , АWS Container Registry, Google Container
Registry и т. д.
У одного образа может быть несколько версий с разными тегами. В реестр образы
загружаются с помощью команды push, а извлекаются из него помощью команды pull.
### 1. Portainer — веб-интерфейс для Docker
```bash
docker volume create portainer_data
docker run -d -p 9000:9000 \
  --name portainer \
  --restart always \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v portainer_data:/data \
  portainer/portainer-ce
```

### 2. ctop — топ для контейнеров
```bash
docker run --rm -ti \
  --name=ctop \
  --volume /var/run/docker.sock:/var/run/docker.sock:ro \
  quay.io/vektorlab/ctop:latest
```

### 3. Dive — анализ Docker образов
```bash
docker run --rm -it \
  -v /var/run/docker.sock:/var/run/docker.sock \
  wagoodman/dive:latest <image>
```

## Производительность и оптимизация

### 1. Оптимизация Dockerfile
```dockerfile
# Плохо
FROM ubuntu:latest
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN pip3 install numpy pandas scikit-learn

# Хорошо
FROM python:3.11-slim
RUN pip install --no-cache-dir numpy pandas scikit-learn

# Еще лучше (многостадийная сборка)
FROM python:3.11 as builder
RUN pip install --user numpy pandas scikit-learn

FROM python:3.11-slim
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH
```

### 2. Настройка демона Docker
```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "storage-driver": "overlay2",
  "dns": ["8.8.8.8", "8.8.4.4"],
  "registry-mirrors": ["https://mirror.gcr.io"],
  "default-ulimits": {
    "nofile": {
      "Name": "nofile",
      "Hard": 65535,
      "Soft": 65535
    }
  }
}
```

## Работа в production

### 1. Docker Swarm (встроенная оркестрация)
```bash
# Инициализация Swarm
docker swarm init --advertise-addr <MANAGER-IP>

# Присоединение worker
docker swarm join --token <TOKEN> <MANAGER-IP>:2377

# Развертывание сервиса
docker service create --name web --replicas 3 -p 80:80 nginx

# Масштабирование
docker service scale web=5

# Обновление сервиса
docker service update --image nginx:latest web

# Просмотр сервисов
docker service ls
docker service ps web

# Создание сети overlay
docker network create --driver overlay mynet

# Docker Stack (Compose в Swarm)
docker stack deploy -c docker-compose.yml myapp
```

### 2. Healthcheck в production
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: myapp:prod
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
```

## Ошибки и их решение

### Распространенные проблемы:

1. **"Cannot connect to the Docker daemon"**
```bash
# Проверка статуса демона
sudo systemctl status docker

# Запуск демона
sudo systemctl start docker

# Добавление пользователя в группу docker
sudo usermod -aG docker $USER
# Перелогиниться или выполнить:
newgrp docker
```

2. **"Port is already allocated"**
```bash
# Поиск контейнера, использующего порт
docker ps --format "table {{.Names}}\t{{.Ports}}"

# Остановка контейнера
docker stop <container_name>

# Или изменение порта
docker run -p 8080:80 nginx  # вместо 80:80
```

3. **"No space left on device"**
```bash
# Очистка неиспользуемых данных
docker system prune -a

# Очистка с подтверждением
docker system prune

# Удаление всех остановленных контейнеров, сетей, образов
docker system prune --volumes
```

4. **Проблемы с DNS в контейнерах**
```bash
# Создание сети с пользовательским DNS
docker network create --driver bridge \
  --subnet 172.28.0.0/16 \
  --ip-range 172.28.5.0/24 \
  --gateway 172.28.5.254 \
  --opt "com.docker.network.driver.mtu"="1500" \
  --opt "com.docker.network.bridge.enable_icc"="true" \
  mynetwork
```

## Заключение и дальнейшее развитие

### Что изучать дальше:

1. **Kubernetes** — промышленная оркестрация контейнеров
2. **Docker Security** — безопасная работа с контейнерами
3. **CI/CD с Docker** — автоматизация сборки и деплоя
4. **Service Mesh** — Istio, Linkerd для микросервисов
5. **Cloud Native технологии** — Prometheus, Grafana, ELK Stack

### Ресурсы для углубленного изучения:

1. **Официальная документация**: docs.docker.com
2. **Dockerfile Best Practices**: https://docs.docker.com/develop/develop-images/dockerfile_best-practices/
3. **Docker Security**: https://docs.docker.com/engine/security/
4. **Docker Bench Security**: https://github.com/docker/docker-bench-security

### Ключевые принципы для запоминания:

1. **Контейнеры должны быть одноразовыми** — легко создаваться и удаляться
2. **Один процесс на контейнер** — следуйте принципу единственной ответственности
3. **Не храните данные в контейнерах** — используйте тома
4. **Используйте легкие образы** — alpine, slim версии
5. **Тегируйте явно** — избегайте latest в production
6. **Пишите эффективные Dockerfile** — многостадийные сборки, кэширование
7. **Мониторьте ресурсы** — ограничивайте CPU и память
8. **Сканируйте образы на уязвимости** — используйте docker scan

Эта энциклопедия покрывает 95% задач, с которыми вы столкнетесь при работе с Docker. Практикуйтесь, начинайте с простых контейнеров и постепенно переходите к сложным многоконтейнерным приложениям. Помните: лучший способ изучить Docker — использовать его в реальных проектах!